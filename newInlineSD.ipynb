{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreNzQuiN/Collab_Stable-Diffusion/blob/main/newInlineSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**1.1 START TEXT2IMG SD**\n",
        "!pip install -q --upgrade diffusers invisible_watermark transformers accelerate safetensors compel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionXLPipeline, DDIMScheduler #EulerAncestralDiscreteScheduler,\n",
        "\n",
        "# model = \"linaqruf/animagine-xl\"\n",
        "# pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "#     model,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     use_safetensors=True,\n",
        "#     safety_checker = None,\n",
        "#     requires_safety_checker = False,\n",
        "#     variant=\"fp16\",\n",
        "#     )\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"cagliostrolab/animagine-xl-4.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "    add_watermarker=False\n",
        "    )\n",
        "\n",
        "pipe.scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe.to('cuda')\n"
      ],
      "metadata": {
        "id": "yOZXfJRCqFg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**1.2 START IMG2IMG SD**\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
      ],
      "metadata": {
        "id": "EgM8KpjQpmn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=0\n",
        "prompt_num=0\n",
        "def disabled_safety_checker(images, clip_input):\n",
        "    if len(images.shape)==4:\n",
        "        num_images = images.shape[0]\n",
        "        return images, [False]*num_images\n",
        "    else:\n",
        "        return images, False\n",
        "pipe.safety_checker = disabled_safety_checker"
      ],
      "metadata": {
        "id": "TX5cV32X0-yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import torch, gc\n",
        "\n",
        "textFile = open(f\"prompt{prompt_num}.txt\", \"a\")\n",
        "\n",
        "amount = 25 #@param {type:'integer'}\n",
        "prompt = \"1girl, goldenglow \\(arknights\\), arknights \\(series\\), dutch angle, looking at viewer, cgdct, cute, solo, smile, light particles, casual, beautiful background, blush, outdoors, park, medium breast, from front, depth of field, very smooth line, year 2024, masterpiece, high score, great score, absurdres\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing finger, extra digits, fewer digits, cropped, worst quality, low quality, low score, bad score, average score, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "outputbase = \"/content/anime_girl\" #@param {type:'string'}\n",
        "startNum = num\n",
        "\n",
        "# compel = Compel(\n",
        "#   tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "#   text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "#   returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "#   requires_pooled=[False, True]\n",
        "# )\n",
        "# conditioning, pooled = compel(prompt)\n",
        "W = 1024 #@param {type:'integer'}\n",
        "H = 1424 #@param {type:'integer'}\n",
        "guidance_scale = 5 #@param {type:'number'}\n",
        "guidance_rescale = 0.9 #@param {type:'number'}\n",
        "num_inference_steps = 28 #@param {type:'integer'}\n",
        "rand = True #@param {type:'boolean'}\n",
        "start = time.time()\n",
        "arrayTime = []\n",
        "\n",
        "for x in range(amount):\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  start = time.time()\n",
        "  if rand == True:\n",
        "    setseed = random.randint(100000,10000000)\n",
        "  else:\n",
        "    seed = 6 #@param {type:'integer'}\n",
        "    setseed = seed\n",
        "  image = pipe(\n",
        "      # prompt_embeds=conditioning, pooled_prompt_embeds=pooled,\n",
        "      prompt=prompt,\n",
        "      negative_prompt=negative_prompt,\n",
        "      seed=setseed,\n",
        "      width=W,\n",
        "      height=H,\n",
        "      guidance_scale=guidance_scale,\n",
        "      guidance_rescale=guidance_rescale,\n",
        "      target_size=(W,H),\n",
        "      original_size=(4096,4096),\n",
        "      num_inference_steps=num_inference_steps,\n",
        "      truncation=True\n",
        "      ).images[0]\n",
        "  output=f\"{outputbase}{num}_{setseed}.png\"\n",
        "  image.save(output)\n",
        "  image = Image.open(output)\n",
        "  plt.imshow(image)\n",
        "  end = time.time()\n",
        "  length = end - start\n",
        "  arrayTime.append(length)\n",
        "  num=num+1\n",
        "\n",
        "end = time.time()\n",
        "length = end - start\n",
        "print(\"It took\", length/60, \"minutes\", length%60, \"seconds!\")\n",
        "textFile.write(f\"\\n\\nTITLE: {startNum}--{num-1} {outputbase} {W}x{H}px\\n + {prompt}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps} {length}\")\n",
        "textFile.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "P69H37DAqHC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "T4hxHQY6y4WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**2.2 PLAY IMG2IMG SD**\n",
        "url = \"\"\n",
        "init_image = load_image(url).convert(\"RGB\")\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "image = pipe(prompt, image=init_image).images"
      ],
      "metadata": {
        "id": "PrI49jkhqlbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "BJns1uUM8K1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **REMOVE ALL**\n",
        "!rm \"/content/\"*.png"
      ],
      "metadata": {
        "id": "43cmSm8zEEO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm f\"/content/{outputbase}{num-1}_{setseed}.png\""
      ],
      "metadata": {
        "id": "q6i9CLxwrXk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **3.3 Connect & Save to Google Drive**\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "x = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "\n",
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/{x}\"\n",
        "\n",
        "!mv \"/content/\"*.png \"/content/drive/MyDrive/Colab Notebooks/{x}\"\n",
        "!mv \"/content/\"*.txt \"/content/drive/MyDrive/Colab Notebooks/{x}\""
      ],
      "metadata": {
        "id": "aFqO2Idf9bFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dir {dir}"
      ],
      "metadata": {
        "id": "CluOv9T87XmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "id": "6cSWetfP-gk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/\"*.png \"/content/outputs\""
      ],
      "metadata": {
        "id": "j3jOiql0-pSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!smi-nvidia"
      ],
      "metadata": {
        "id": "foJEWcrREsiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}